# Cache

## Cache的基本概念和原理

### 局部性原理

#### 空间局部性

数组元素、顺序执行的指令代码

在最近的未来要用到的信息（指令和数据），很可能与现在正在使用的信息在存储空间上是邻近的

#### 时间局部性

循环结构的指令代码

在最近的未来要用到的信息，很可能是现在正在使用的信息

```c++
int sumarrayrows(int a[M][N])
{
    int i, j, sum = 0;
    for(i=0;i<M;i++)
        for(j=0;j<N;j++)
            sum+=a[i][j];
    return sum;
}
```

程序B按“列优先”访问二维数组，空间局部性更差

```c++
int sumarrayrows(int a[M][N])
{
    int i, j, sum = 0;
    for(j=0;j<N;j++)
    	for(i=0;i<M;i++)
            sum+=a[i][j];
    return sum;
}
```

基于局部性原理，不难想到，可以把CPU目前访问的地址“周围”的部分数据放到Cache中

![](1.png)

### 性能分析

设tc位访问一次Cache所需时间，tm为访问一次主存所需时间

命中率H：CPU欲访问的信息已在Cache中的比率

缺失（未命中）率M=1-H

Cache-主存系统的平均访问时间t为

先访问Cache，若Cache未命中再访问主存
$$
t=Ht_c+(1-H)(t_c+t_m)
$$
同时访问Cache和主存，若Cache命中则立即停止访问主存
$$
t=Ht_c+(1-H)t_m
$$
![](2.png)

![](3.png)

### 有待解决的问题

基于局部性原理，不难想到，可以把CPU目前访问的地址“周围”的部分数据放到Cache中。如何界定“周围“？

将主存的存储空间”分块“，如：每1kB为一块。主存与Cache之间以“块”为单位进行数据交换

![](4.png)

注：操作系统中，通常将主存中的“一个块”也成为“一个页/页面/页框”

Cache中的“块“也称为”行“

注意：每次被访问的主存块，一定会被立即调入Cache

如何区分Cache与主存的数据块对应关系？Cache和主存的映射方式

Cache很小，主存很大。如果Cache满了怎么办？替换算法

CPU修改了Cache中的数据副本，如果确保主存中数据母本的一致性？Cache写策略

![](5.png)

## Cache和主存的映射方式

如何区分Cache中存放的是哪个主存块？

给每个Cache块增加一个”标记“，记录对应的主存块号？

有”标记“就够了？

还要增加”有效位“



![](6.png)

### 全相联映射（随意放）

主存块可以放在Cache的任意位置

![](7.png)

### 直接映射

每个主存块只能放到一个特定的位置：
$$
Cache块号=主存块号\%Cache总块数
$$
![](8.png)

![](9.png)

![](10.png)

### 组相联映射

Cache块分为若干组，每个主存块可放到特定分组中的任意一个位置组号
$$
组号=主存块号\%分组数
$$
![](11.png)

![](12.png)

结合每种地址映射方式的地址结构思考：给定一个主存地址，如何拆分地址，并查找Cache、访存？

## Cache替换算法

### 替换算法解决的问题

![](13.png)

1. 全相联映射

   Cache完全满了才需要替换需要在全局选择替换哪一块

2. 直接映射

   如果对应位置非空，则毫无选择地直接替换

3. 组相联映射

   分组内满了才需要替换

   需要在分组内选择替换哪一块

![](14.png)

### 随机算法（RAND）

随机算法（RAND，Random）若Cache已满，则随机选择一块替换。

设总共有4个Cache块，初始整个Cache为空。采用全相联映射，依次访问主存块

{1，2，3，4，1，2，5，1，2，3，4，5}

![](15.png)

随机算法 实现简单，但完全没考虑局部性原理，命中率低，实际效果很不稳定

### 先进先出算法（FIFO）

先进先出算法（FIFO，First In First Out）若Cache已满，则替换最先被调入Cache的块

设总共有4个Cache块，初始整个Cache为空。采用全相联映射，依次访问主存块{1，2，3，4，1，2，5，1，2，3，4，5}

![](16.png)

先进先出算法 实现简单，最开始按#0#1#2#3放入Cache，之后轮流替换#0#1#2#3FIFO依然没考虑局部性原理，最先被调入Cache的块也有可能是被频繁访问的

抖动现象：频繁的换入换出现象（刚被替换的块很快又被调入）

### 近期最少使用算法（LRU）

近期最少使用算法（LRU，Least Recently Used）为每一个Cache块设置一个”计数器“，用于记录每个Cache块已经有多久没被访问了。当Cache满后替换”计数器“最大的

设总共有4个Cache块，初始整个Cache为空。采用全相联映射，依次访问主存块{1，2，3，4，1，2，5，1，2，3，4，5}

![](17.png)

1. 命中时，所命中的行的计数器清零，比其低的计数器加1，其余不变；
2. 未命中且还有空闲行时，新装入的行的计数器置0，其余非空闲行全加1；
3. 未命中且无空闲行时，计数值最大的行的信息块被淘汰，新装行的块的计数器置0，其余全加1。

LRU算法 基于"局部性原理"，近期被访问过的主存块，在不久的将来也很有可能被再次访问，因此淘汰最久没被访问过的块是合理的。LRU算法的实际运行效果优秀，Cache命中率高。

若被频繁访问的主存块数量>Cache行的数量，则有可能发生“抖动”，如：{1，2，3，4，5，1，2，3，4，5，1，2...}

### 最不经常使用算法（LFU）

最不经常使用算法（LFU，Least Frequently Used）为每一个Cache块设置一个“计数器”，用于记录每个Cache块被访问过几次。当Cache满后替换”计数器“最小的

设总共有4个Cache块，初始整个Cache为空。采用全相联映射，依次访问主存块{1，2，3，4，1，2，5，1，2，3，4，5}

![](18.png)

新调入的块计数器=0，之后每被访问一次计数器+1。需要替换时，选择计数器最小的一行

注：若采用FIFO策略，则会淘汰4号主存块

LFU算法 曾经被访问的主存块在未来不一定会用到（如：微信视频聊天相关的块），并没有很好地遵循局部性原理，因此实际运行效果不如LRU

![](19.png)

## Cache写策略

![](20.png)

为何不讨论读命中、读不命中的情况？

读操作不会导致Cache和主存的数据不一致

### 写命中

#### 写回法

![](21.png)

写回法（write-back）当CPU对Cache命中时，只修改Cache的内容，而不立即写入主存，只有当此块被换出时才写回主存

减少了访存次数，但存在数据不一致的隐患。

#### 全写法

![](22.png)

全写法（写直通法，write-through）当CPU对Cache写命中时，必须把数据同时写入Cache和主存，一般使用写缓冲（write buffer）

访存次数增加，速度变慢，但更能保证数据一致性

![](23.png)

使用写缓冲，CPU写的速度很快，若写操作不频繁，则效果很好。若写操作很频繁，可能会因为写缓冲饱和而发生阻塞

### 写不命中

#### 写分配法

写分配法（write-allocate）当CPU对Cache写不命中时，把主存中的块调入Cache，在Cache中修改。通常搭配写回法使用。

写回法（write-back）当CPU对Cache写命中时，只修改Cache的内容，而不立即写入主存，只有当此块被换出时才写回主存

![](24.png)

#### 非写分配法

![](25.png)

非写分配法（not-write-allocate）当CPU对Cache写不命中时只写入主存，不调入Cache。

搭配全写法使用。

全写法（写直通法，write-through）当CPU对Cache写命中时，必须把数据同时写入Cache和主存，一般使用写缓冲（write buffer）

### 多级Cache

![](26.png)

![](27.png)

# 页式存储器

## 页式存储

页式存储系统：一个程序（进程）在逻辑上被分为若干个大小相等的“页面”，“页面”大小与“块”的大小相同。每个页面可以离散地放入不同的主存块中。

![](28.png)

## 虚地址vs实地址

逻辑地址（虚地址）：程序员视角看到的地址

物理地址（实地址）：实际在主存中的地址

![](29.png)

## 页表：逻辑页号 -> 主存块号

CPU执行的机器指令中，使用的是“逻辑地址”，因此需要通”页表“将逻辑地址转为物理地址。

页表的作用：记录了每个逻辑页面存放在哪个主存块中

## 地址变换过程

![](30.png)

## 地址变换过程（增加TLB）

注意区别：快表中存储的是页表项的副本；Cache中存储的是主存块的副本

快表是一种“相联存储器”可以按内容寻访

![](31.png)

![](32.png)

页式存储系统：一个程序在逻辑上被分为若干个大小相等的“页面”，“页面”大小与“块”的大小相同。每个页面可以离散地放入不同的主存块中。

逻辑地址=逻辑页号+页内地址

虚地址=虚页号+页内地址

物理地址=主存块号+页内地址

实地址=实页号+页内地址

注意区别：快表中存储的是页表项的副本；Cache中存储的是主存块的副本

![](33.png)

# 虚拟存储器

## 套娃警告：虚拟存储系统

思考：打游戏时候的”Loading“界面背后是在干嘛？

将游戏地图相关数据调入内存

## 页式虚拟存储器

![](34.png)

- 有效位：这个页面是否已调入主存
- 脏位：这个页面是否被修改过
- 引用位：用于“页面置换算法”，比如，可以用来统计这个页面被访问过多少次
- 物理页：即主存块号
- 磁盘地址：即这个页面的数据在磁盘中的存放位置

## 存储器的层次化结构

主存-辅存：实现虚拟存储系统，解决了主存容量不够的问题

操作系统决定，哪些页面调入主存

Cache-主存：解决了主存与CPU速度不匹配的问题

硬件决定，哪些主存块调入Cache

![](35.png)

## 段式虚拟存储器

![](36.png)

页式虚拟存储器 拆分成大小相等的页面

![](37.png)

段式虚拟存储器 按照功能模块拆分 如：#0段是自己的代码，#1段是库函数代码，#2段是变量

![](38.png)

## 段页式虚拟存储器

把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页，程序对主存的调入、调出仍以页为基本传送单位。每个程序对应一个段表，每段对应一个页表。

虚拟地址：段号+段内页号+页内地址

段页式虚拟存储器 按照功能模块分段，再将各个段分页

![](39.png)